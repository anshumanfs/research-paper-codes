{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd71435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas scikit-learn xgboost openpyxl torch matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f43221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ensure openpyxl is installed\n",
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing optional dependency 'openpyxl'. Install it using: pip install openpyxl\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\".\\Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Defining color and spectral feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "spectral_columns = [f\"R{wavelength} nm\" for wavelength in range(400, 710, 10)]\n",
    "\n",
    "# Selecting features\n",
    "color_features = df[color_columns]  # Nix color data\n",
    "spectral_features = df[spectral_columns]  # Nix spectral data\n",
    "y = df[\"O.C (%)\"]   # Target variable\n",
    "\n",
    "# Splitting the dataset into 70% training and 30% validation\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(color_features, y, test_size=0.3, random_state=42)\n",
    "X_train_spectral, X_val_spectral, _, _ = train_test_split(spectral_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "scaler_spectral = StandardScaler()\n",
    "X_train_spectral_scaled = scaler_spectral.fit_transform(X_train_spectral)\n",
    "X_val_spectral_scaled = scaler_spectral.transform(X_val_spectral)\n",
    "\n",
    "# Initialize models\n",
    "best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate using Color Data\n",
    "best_model.fit(X_train_color_scaled, y_train)\n",
    "y_pred_color_val = best_model.predict(X_val_color_scaled)\n",
    "r2_color_val = r2_score(y_val, y_pred_color_val)\n",
    "\n",
    "# Train and evaluate using Spectral Data\n",
    "best_model.fit(X_train_spectral_scaled, y_train)\n",
    "y_pred_spectral_val = best_model.predict(X_val_spectral_scaled)\n",
    "r2_spectral_val = r2_score(y_val, y_pred_spectral_val)\n",
    "\n",
    "# Correlation Analysis\n",
    "color_corr = color_features.corrwith(y)\n",
    "spectral_corr = spectral_features.corrwith(y)\n",
    "\n",
    "# Plot Color Data Correlation\n",
    "plt.figure(figsize=(8, 5))\n",
    "color_corr.sort_values().plot(kind='barh', color=plt.cm.Blues(np.linspace(0.3, 1, len(color_corr))))\n",
    "plt.xlabel(\"Correlation Coefficient\", fontweight='bold')\n",
    "plt.ylabel(\"Color Features\", fontweight='bold')\n",
    "plt.title(\"Correlation between Color Data and OC\", fontweight='bold')\n",
    "plt.savefig(\"color_oc_correlation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot Spectral Data Correlation\n",
    "plt.figure(figsize=(8, 5))\n",
    "spectral_corr.sort_values().plot(kind='barh', color=plt.cm.Blues(np.linspace(0.3, 1, len(spectral_corr))))\n",
    "plt.xlabel(\"Correlation Coefficient\", fontweight='bold')\n",
    "plt.ylabel(\"Spectral Features\", fontweight='bold')\n",
    "plt.title(\"Correlation between Spectral Data and OC\", fontweight='bold')\n",
    "plt.savefig(\"spectral_oc_correlation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot OC Distribution with Smooth Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(y, bins=20, color='darkgreen', edgecolor='black', alpha=0.7)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.gaussian_kde(y)(x)\n",
    "plt.plot(x, p * len(y) * (xmax - xmin) / 20, color='black', linewidth=2)\n",
    "plt.xlabel(\"OC (%)\", fontweight='bold')\n",
    "plt.ylabel(\"Frequency\", fontweight='bold')\n",
    "plt.title(\"Distribution of OC\", fontweight='bold')\n",
    "plt.savefig(\"oc_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Prediction Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Color Data Plot\n",
    "axes[0].scatter(y_val, y_pred_color_val, color='red', marker='^', s=100, label='Validation Samples')\n",
    "axes[0].plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], linestyle='--', color='blue', label='1:1 Line')\n",
    "axes[0].plot(np.unique(y_val), np.poly1d(np.polyfit(y_val, y_pred_color_val, 1))(np.unique(y_val)), color='black', label='Regression Line')\n",
    "axes[0].set_xlabel(\"Measured OC (%)\", fontweight='bold')\n",
    "axes[0].set_ylabel(\"Predicted OC (%)\", fontweight='bold')\n",
    "axes[0].set_title(\"Color Data Prediction\", fontweight='bold')\n",
    "axes[0].text(min(y_val), max(y_pred_color_val), f'R² = {r2_color_val:.2f}', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Spectral Data Plot\n",
    "axes[1].scatter(y_val, y_pred_spectral_val, color='red', marker='^', s=100, label='Validation Samples')\n",
    "axes[1].plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], linestyle='--', color='blue', label='1:1 Line')\n",
    "axes[1].plot(np.unique(y_val), np.poly1d(np.polyfit(y_val, y_pred_spectral_val, 1))(np.unique(y_val)), color='black', label='Regression Line')\n",
    "axes[1].set_xlabel(\"Measured OC (%)\", fontweight='bold')\n",
    "axes[1].set_ylabel(\"Predicted OC (%)\", fontweight='bold')\n",
    "axes[1].set_title(\"Spectral Data Prediction\", fontweight='bold')\n",
    "axes[1].text(min(y_val), max(y_pred_spectral_val), f'R² = {r2_spectral_val:.2f}', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prediction_plots.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ensure openpyxl is installed\n",
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing optional dependency 'openpyxl'. Install it using: pip install openpyxl\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\".\\Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Defining color and spectral feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "spectral_columns = [f\"R{wavelength} nm\" for wavelength in range(400, 710, 10)]\n",
    "\n",
    "# Selecting features\n",
    "color_features = df[color_columns]  # Nix color data\n",
    "spectral_features = df[spectral_columns]  # Nix spectral data\n",
    "y = df[\"O.C (%)\"]   # Target variable\n",
    "\n",
    "# Splitting the dataset into 70% training and 30% validation\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(color_features, y, test_size=0.3, random_state=42)\n",
    "X_train_spectral, X_val_spectral, _, _ = train_test_split(spectral_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "scaler_spectral = StandardScaler()\n",
    "X_train_spectral_scaled = scaler_spectral.fit_transform(X_train_spectral)\n",
    "X_val_spectral_scaled = scaler_spectral.transform(X_val_spectral)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100,50), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train and evaluate using Color Data\n",
    "    model.fit(X_train_color_scaled, y_train)\n",
    "    y_pred_color_train = model.predict(X_train_color_scaled)\n",
    "    y_pred_color_val = model.predict(X_val_color_scaled)\n",
    "    r2_color_train = r2_score(y_train, y_pred_color_train)\n",
    "    rmse_color_train = np.sqrt(mean_squared_error(y_train, y_pred_color_train))\n",
    "    bias_color_train = np.mean(y_pred_color_train - y_train)\n",
    "    r2_color_val = r2_score(y_val, y_pred_color_val)\n",
    "    rmse_color_val = np.sqrt(mean_squared_error(y_val, y_pred_color_val))\n",
    "    bias_color_val = np.mean(y_pred_color_val - y_val)\n",
    "    \n",
    "    # Train and evaluate using Spectral Data\n",
    "    model.fit(X_train_spectral_scaled, y_train)\n",
    "    y_pred_spectral_train = model.predict(X_train_spectral_scaled)\n",
    "    y_pred_spectral_val = model.predict(X_val_spectral_scaled)\n",
    "    r2_spectral_train = r2_score(y_train, y_pred_spectral_train)\n",
    "    rmse_spectral_train = np.sqrt(mean_squared_error(y_train, y_pred_spectral_train))\n",
    "    bias_spectral_train = np.mean(y_pred_spectral_train - y_train)\n",
    "    r2_spectral_val = r2_score(y_val, y_pred_spectral_val)\n",
    "    rmse_spectral_val = np.sqrt(mean_squared_error(y_val, y_pred_spectral_val))\n",
    "    bias_spectral_val = np.mean(y_pred_spectral_val - y_val)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"Color R² (Train)\": r2_color_train, \"Color RMSE (Train)\": rmse_color_train, \"Color Bias (Train)\": bias_color_train,\n",
    "        \"Color R² (Val)\": r2_color_val, \"Color RMSE (Val)\": rmse_color_val, \"Color Bias (Val)\": bias_color_val,\n",
    "        \"Spectral R² (Train)\": r2_spectral_train, \"Spectral RMSE (Train)\": rmse_spectral_train, \"Spectral Bias (Train)\": bias_spectral_train,\n",
    "        \"Spectral R² (Val)\": r2_spectral_val, \"Spectral RMSE (Val)\": rmse_spectral_val, \"Spectral Bias (Val)\": bias_spectral_val,\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "print(results_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"model_performance.csv\", index=True)\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ensure openpyxl is installed\n",
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing optional dependency 'openpyxl'. Install it using: pip install openpyxl\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\".\\Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Selecting features\n",
    "color_features = df.iloc[:, 3:9]  # Nix color data\n",
    "spectral_features = df.iloc[:, 9:]  # Nix spectral data\n",
    "y = df[\"O.C (%)\"]   # Target variable\n",
    "\n",
    "# Splitting the dataset into 70% training and 30% validation\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(color_features, y, test_size=0.3, random_state=42)\n",
    "X_train_spectral, X_val_spectral, _, _ = train_test_split(spectral_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "scaler_spectral = StandardScaler()\n",
    "X_train_spectral_scaled = scaler_spectral.fit_transform(X_train_spectral)\n",
    "X_val_spectral_scaled = scaler_spectral.transform(X_val_spectral)\n",
    "\n",
    "# Initialize models\n",
    "best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate using Color Data\n",
    "best_model.fit(X_train_color_scaled, y_train)\n",
    "y_pred_color_train = best_model.predict(X_train_color_scaled)\n",
    "y_pred_color_val = best_model.predict(X_val_color_scaled)\n",
    "\n",
    "# Train and evaluate using Spectral Data\n",
    "best_model.fit(X_train_spectral_scaled, y_train)\n",
    "y_pred_spectral_train = best_model.predict(X_train_spectral_scaled)\n",
    "y_pred_spectral_val = best_model.predict(X_val_spectral_scaled)\n",
    "\n",
    "# Save calibration and validation samples with predicted values\n",
    "df_train = pd.DataFrame(X_train_color, columns=color_features.columns)\n",
    "df_train[\"Measured O.C (%)\"] = y_train\n",
    "df_train[\"Predicted O.C (%)\"] = y_pred_color_train\n",
    "df_train[\"Type\"] = \"Calibration\"\n",
    "\n",
    "df_val = pd.DataFrame(X_val_color, columns=color_features.columns)\n",
    "df_val[\"Measured O.C (%)\"] = y_val\n",
    "df_val[\"Predicted O.C (%)\"] = y_pred_color_val\n",
    "df_val[\"Type\"] = \"Validation\"\n",
    "\n",
    "df_combined = pd.concat([df_train, df_val])\n",
    "df_combined.to_csv(\"calibration_validation_samples.csv\", index=False)\n",
    "print(\"Calibration and validation samples with predicted values saved to 'calibration_validation_samples.csv'.\")\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ensure openpyxl is installed\n",
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing optional dependency 'openpyxl'. Install it using: pip install openpyxl\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\".\\Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Defining color feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "\n",
    "# Selecting features\n",
    "color_features = df[color_columns]  # Nix color data\n",
    "y = df[\"O.C (%)\"]   # Target variable\n",
    "\n",
    "# Splitting the dataset into 70% training and 30% validation\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(color_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "# Convert scaled data back to DataFrame\n",
    "X_train_color_scaled_df = pd.DataFrame(X_train_color_scaled, columns=color_columns, index=X_train_color.index)\n",
    "X_val_color_scaled_df = pd.DataFrame(X_val_color_scaled, columns=color_columns, index=X_val_color.index)\n",
    "\n",
    "# Initialize models\n",
    "best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate using Color Data\n",
    "best_model.fit(X_train_color_scaled, y_train)\n",
    "y_pred_color_train = best_model.predict(X_train_color_scaled)\n",
    "y_pred_color_val = best_model.predict(X_val_color_scaled)\n",
    "\n",
    "# Save calibration and validation samples with predicted values\n",
    "df_train = X_train_color.copy()\n",
    "df_train[\"Measured O.C (%)\"] = y_train\n",
    "df_train[\"Predicted O.C (%)\"] = y_pred_color_train\n",
    "df_train[\"Type\"] = \"Calibration\"\n",
    "\n",
    "df_val = X_val_color.copy()\n",
    "df_val[\"Measured O.C (%)\"] = y_val\n",
    "df_val[\"Predicted O.C (%)\"] = y_pred_color_val\n",
    "df_val[\"Type\"] = \"Validation\"\n",
    "\n",
    "df_combined = pd.concat([df_train, df_val])\n",
    "import datetime\n",
    "output_filename = f\"calibration_validation_samples_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df_combined.to_csv(output_filename, index=False)\n",
    "print(\"Calibration and validation samples with predicted values saved to 'calibration_validation_samples.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c625b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"./Nix.xlsx\"  # Adjust path if needed\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "y = df[\"O.C (%)\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(df[color_columns], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize training features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "\n",
    "# Store results\n",
    "results_gmm = []\n",
    "synthetic_sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "oc_thresholds = list(range(4, 15))\n",
    "\n",
    "for num_samples in synthetic_sizes:\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    gmm.fit(X_train_color_scaled)\n",
    "    synthetic_features = gmm.sample(num_samples)[0]\n",
    "    synthetic_oc = np.random.uniform(y_train.min(), y_train.max(), num_samples)\n",
    "\n",
    "    for upper_limit in oc_thresholds:\n",
    "        synthetic_df = pd.DataFrame(synthetic_features, columns=color_columns)\n",
    "        synthetic_df[\"O.C (%)\"] = synthetic_oc\n",
    "        synthetic_df = synthetic_df[(synthetic_df[\"O.C (%)\"] >= 3) & (synthetic_df[\"O.C (%)\"] <= upper_limit)]\n",
    "\n",
    "        # Train Model\n",
    "        if not synthetic_df.empty:\n",
    "            # Merge original training data with synthetic data\n",
    "            train_data = pd.concat([X_train_color, y_train], axis=1).reset_index(drop=True)\n",
    "            synthetic_df = synthetic_df.reset_index(drop=True)\n",
    "            train_data = pd.concat([train_data, synthetic_df]).reset_index(drop=True)\n",
    "\n",
    "            X_train_final = train_data[color_columns]\n",
    "            y_train_final = train_data[\"O.C (%)\"]\n",
    "\n",
    "            # ✅ Ensure Validation Features Match the Training Column Order\n",
    "            X_val_final = X_val_color[color_columns]  # This guarantees same column order\n",
    "\n",
    "            # Standardize both train and validation sets\n",
    "            scaler_final = StandardScaler()\n",
    "            X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "            X_val_final_scaled = scaler_final.transform(X_val_final)\n",
    "\n",
    "            # Train RandomForest model\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "            y_pred = rf_model.predict(X_val_final_scaled)\n",
    "\n",
    "            # Compute performance metrics\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            results_gmm.append({\n",
    "                \"Sample Size\": num_samples,\n",
    "                \"OC Range\": f\"3-{upper_limit}%\",\n",
    "                \"R²\": r2,\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "df_gmm = pd.DataFrame(results_gmm)\n",
    "output_path = \"GMM_Results_ALL.xlsx\"\n",
    "df_gmm.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ GMM results saved successfully: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58072ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "y = df[\"O.C (%)\"]\n",
    "\n",
    "# Split dataset (70% training, 30% validation)\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(df[color_columns], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train_color_scaled, X_train_color_scaled)\n",
    "\n",
    "# Define synthetic dataset sizes and OC thresholds\n",
    "synthetic_sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "oc_thresholds = list(range(4, 15))\n",
    "\n",
    "# Store results\n",
    "results_knn = []\n",
    "\n",
    "for num_samples in synthetic_sizes:\n",
    "    # Generate synthetic features using KNN\n",
    "    synthetic_features = knn.predict(X_train_color_scaled[:min(num_samples, len(X_train_color_scaled))])\n",
    "    synthetic_oc = np.random.uniform(y_train.min(), y_train.max(), len(synthetic_features))\n",
    "\n",
    "    for upper_limit in oc_thresholds:\n",
    "        # Create a DataFrame for synthetic data\n",
    "        synthetic_df = pd.DataFrame(synthetic_features, columns=color_columns)\n",
    "        synthetic_df[\"O.C (%)\"] = synthetic_oc[:len(synthetic_df)]  # Ensure matching length\n",
    "        synthetic_df = synthetic_df[(synthetic_df[\"O.C (%)\"] >= 3) & (synthetic_df[\"O.C (%)\"] <= upper_limit)]\n",
    "\n",
    "        # Train Model\n",
    "        if not synthetic_df.empty:\n",
    "            # Combine training data with synthetic data\n",
    "            train_data = pd.concat([X_train_color, y_train], axis=1)\n",
    "            train_data = pd.concat([train_data, synthetic_df])\n",
    "\n",
    "            X_train_final = train_data[color_columns]\n",
    "            y_train_final = train_data[\"O.C (%)\"]\n",
    "\n",
    "            # Standardize the combined dataset\n",
    "            scaler_final = StandardScaler()\n",
    "            X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "            X_val_final_scaled = scaler_final.transform(X_val_color)\n",
    "\n",
    "            # Train Random Forest Model\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "            y_pred = rf_model.predict(X_val_final_scaled)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            # Store results\n",
    "            results_knn.append({\n",
    "                \"Sample Size\": num_samples,\n",
    "                \"OC Range\": f\"3-{upper_limit}%\",\n",
    "                \"R²\": r2,\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "df_knn = pd.DataFrame(results_knn)\n",
    "output_file = \"KNN_Results_ALL.xlsx\"\n",
    "df_knn.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"✅ KNN results saved successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a09dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "y = df[\"O.C (%)\"]\n",
    "\n",
    "# Split dataset (70% training, 30% validation)\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(df[color_columns], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "# Define GAN Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Define function to generate synthetic GAN data\n",
    "def generate_gan_data(generator, num_samples, input_dim):\n",
    "    generator.eval()  # Set to evaluation mode\n",
    "    z = torch.randn(num_samples, input_dim)\n",
    "    synthetic_features = generator(z).detach().numpy()\n",
    "    return scaler_color.inverse_transform(synthetic_features), np.random.uniform(y_train.min(), y_train.max(), num_samples)\n",
    "\n",
    "# Initialize GAN model\n",
    "z_dim = 10  # Latent space dimension\n",
    "generator = Generator(z_dim, X_train_color_scaled.shape[1])\n",
    "\n",
    "# Define synthetic dataset sizes and OC thresholds\n",
    "synthetic_sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "oc_thresholds = list(range(4, 15))\n",
    "\n",
    "# Store results\n",
    "results_gan = []\n",
    "\n",
    "for num_samples in synthetic_sizes:\n",
    "    # Generate synthetic data using GAN\n",
    "    gan_features, gan_oc = generate_gan_data(generator, num_samples, z_dim)\n",
    "\n",
    "    for upper_limit in oc_thresholds:\n",
    "        # Create a DataFrame for synthetic data\n",
    "        synthetic_df = pd.DataFrame(gan_features, columns=color_columns)\n",
    "        synthetic_df[\"O.C (%)\"] = gan_oc[:len(synthetic_df)]  # Ensure matching length\n",
    "        synthetic_df = synthetic_df[(synthetic_df[\"O.C (%)\"] >= 3) & (synthetic_df[\"O.C (%)\"] <= upper_limit)]\n",
    "\n",
    "        # Train Model\n",
    "        if not synthetic_df.empty:\n",
    "            # Combine training data with synthetic data\n",
    "            train_data = pd.concat([X_train_color, y_train], axis=1)\n",
    "            train_data = pd.concat([train_data, synthetic_df])\n",
    "\n",
    "            X_train_final = train_data[color_columns]\n",
    "            y_train_final = train_data[\"O.C (%)\"]\n",
    "\n",
    "            # Standardize the combined dataset\n",
    "            scaler_final = StandardScaler()\n",
    "            X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "            X_val_final_scaled = scaler_final.transform(X_val_color)\n",
    "\n",
    "            # Train Random Forest Model\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "            y_pred = rf_model.predict(X_val_final_scaled)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            # Store results\n",
    "            results_gan.append({\n",
    "                \"Sample Size\": num_samples,\n",
    "                \"OC Range\": f\"3-{upper_limit}%\",\n",
    "                \"R²\": r2,\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "df_gan = pd.DataFrame(results_gan)\n",
    "output_file = \"GAN_Results_ALL.xlsx\"\n",
    "df_gan.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"✅ GAN results saved successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be97d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Nix.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "y = df[\"O.C (%)\"]\n",
    "\n",
    "# Split dataset (70% training, 30% validation)\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(df[color_columns], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "# Define synthetic dataset sizes and OC thresholds\n",
    "synthetic_sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "oc_thresholds = list(range(4, 15))\n",
    "\n",
    "# Store results\n",
    "results_bootstrap = []\n",
    "\n",
    "for num_samples in synthetic_sizes:\n",
    "    # Generate synthetic data using Bootstrapping\n",
    "    bootstrap_features, bootstrap_oc = resample(X_train_color_scaled, y_train.values, \n",
    "                                                n_samples=num_samples, random_state=42)\n",
    "\n",
    "    # Convert bootstrapped features back to original scale\n",
    "    bootstrap_features = scaler_color.inverse_transform(bootstrap_features)\n",
    "\n",
    "    for upper_limit in oc_thresholds:\n",
    "        # Create a DataFrame for synthetic data\n",
    "        synthetic_df = pd.DataFrame(bootstrap_features, columns=color_columns)\n",
    "        synthetic_df[\"O.C (%)\"] = bootstrap_oc[:len(synthetic_df)]  # Ensure matching length\n",
    "        synthetic_df = synthetic_df[(synthetic_df[\"O.C (%)\"] >= 3) & (synthetic_df[\"O.C (%)\"] <= upper_limit)]\n",
    "\n",
    "        # Train Model\n",
    "        if not synthetic_df.empty:\n",
    "            # Combine training data with synthetic data\n",
    "            train_data = pd.concat([X_train_color, y_train], axis=1)\n",
    "            train_data = pd.concat([train_data, synthetic_df])\n",
    "\n",
    "            X_train_final = train_data[color_columns]\n",
    "            y_train_final = train_data[\"O.C (%)\"]\n",
    "\n",
    "            # Standardize the combined dataset\n",
    "            scaler_final = StandardScaler()\n",
    "            X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "            X_val_final_scaled = scaler_final.transform(X_val_color)\n",
    "\n",
    "            # Train Random Forest Model\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "            y_pred = rf_model.predict(X_val_final_scaled)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            # Store results\n",
    "            results_bootstrap.append({\n",
    "                \"Sample Size\": num_samples,\n",
    "                \"OC Range\": f\"3-{upper_limit}%\",\n",
    "                \"R²\": r2,\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "df_bootstrap = pd.DataFrame(results_bootstrap)\n",
    "output_file = \"Bootstrap_Results_ALL.xlsx\"\n",
    "df_bootstrap.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Bootstrap results saved successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c779665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"Nix.xlsx\"  # Update this path if needed\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Defining color and spectral feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "spectral_columns = [f\"R{wavelength} nm\" for wavelength in range(400, 710, 10)]\n",
    "\n",
    "# Selecting features\n",
    "color_features = df[color_columns]  # Nix color data\n",
    "spectral_features = df[spectral_columns]  # Nix spectral data\n",
    "y = df[\"O.C (%)\"]   # Target variable\n",
    "\n",
    "# Splitting the dataset into 70% training and 30% validation\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(color_features, y, test_size=0.3, random_state=42)\n",
    "X_train_spectral, X_val_spectral, _, _ = train_test_split(spectral_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "X_val_color_scaled = scaler_color.transform(X_val_color)\n",
    "\n",
    "scaler_spectral = StandardScaler()\n",
    "X_train_spectral_scaled = scaler_spectral.fit_transform(X_train_spectral)\n",
    "X_val_spectral_scaled = scaler_spectral.transform(X_val_spectral)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100,50), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train and evaluate using Color Data\n",
    "    model.fit(X_train_color_scaled, y_train)\n",
    "    y_pred_color_val = model.predict(X_val_color_scaled)\n",
    "    \n",
    "    r2_color_val = r2_score(y_val, y_pred_color_val)\n",
    "    rmse_color_val = np.sqrt(mean_squared_error(y_val, y_pred_color_val))\n",
    "    bias_color_val = np.mean(y_pred_color_val - y_val)\n",
    "    rpiq_color_val = (np.percentile(y_val, 75) - np.percentile(y_val, 25)) / rmse_color_val\n",
    "    \n",
    "    # Train and evaluate using Spectral Data\n",
    "    model.fit(X_train_spectral_scaled, y_train)\n",
    "    y_pred_spectral_val = model.predict(X_val_spectral_scaled)\n",
    "    \n",
    "    r2_spectral_val = r2_score(y_val, y_pred_spectral_val)\n",
    "    rmse_spectral_val = np.sqrt(mean_squared_error(y_val, y_pred_spectral_val))\n",
    "    bias_spectral_val = np.mean(y_pred_spectral_val - y_val)\n",
    "    rpiq_spectral_val = (np.percentile(y_val, 75) - np.percentile(y_val, 25)) / rmse_spectral_val\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        \"Color R² (Val)\": r2_color_val, \n",
    "        \"Color RMSE (Val)\": rmse_color_val, \n",
    "        \"Color Bias (Val)\": bias_color_val,\n",
    "        \"Color RPIQ (Val)\": rpiq_color_val,\n",
    "        \"Spectral R² (Val)\": r2_spectral_val, \n",
    "        \"Spectral RMSE (Val)\": rmse_spectral_val, \n",
    "        \"Spectral Bias (Val)\": bias_spectral_val,\n",
    "        \"Spectral RPIQ (Val)\": rpiq_spectral_val\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Display results in the console\n",
    "print(results_df)\n",
    "\n",
    "# Save results as CSV\n",
    "results_df.to_csv(r\".\\validation_performance_metrics.csv\", index=True)\n",
    "print(\"Validation performance metrics saved as 'validation_performance_metrics.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Nix.xlsx\"  # Update the path if needed\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define feature columns\n",
    "color_columns = [\"L*\", \"a*\", \"b*\", \"c\", \"h\", \"X\", \"Z\", \"sRGB R\", \"sRGB G\", \"sRGB B\", \"C\", \"M\", \"Y\", \"K\"]\n",
    "y = df[\"O.C (%)\"]\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "X_train_color, X_val_color, y_train, y_val = train_test_split(df[color_columns], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize training features\n",
    "scaler_color = StandardScaler()\n",
    "X_train_color_scaled = scaler_color.fit_transform(X_train_color)\n",
    "\n",
    "# Generate synthetic data using GMM with 5000 samples and OC range 3-7%\n",
    "num_samples = 5000\n",
    "oc_range = (3, 7)\n",
    "\n",
    "gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "gmm.fit(X_train_color_scaled)\n",
    "synthetic_features = gmm.sample(num_samples)[0]\n",
    "synthetic_oc = np.random.uniform(oc_range[0], oc_range[1], num_samples)\n",
    "\n",
    "# Create synthetic DataFrame and filter based on OC range\n",
    "synthetic_df = pd.DataFrame(synthetic_features, columns=color_columns)\n",
    "synthetic_df[\"O.C (%)\"] = synthetic_oc\n",
    "synthetic_df = synthetic_df[(synthetic_df[\"O.C (%)\"] >= oc_range[0]) & (synthetic_df[\"O.C (%)\"] <= oc_range[1])]\n",
    "\n",
    "# Merge original training data with synthetic data\n",
    "train_data = pd.concat([X_train_color, y_train], axis=1).reset_index(drop=True)\n",
    "synthetic_df = synthetic_df.reset_index(drop=True)\n",
    "train_data = pd.concat([train_data, synthetic_df]).reset_index(drop=True)\n",
    "\n",
    "X_train_final = train_data[color_columns]\n",
    "y_train_final = train_data[\"O.C (%)\"]\n",
    "\n",
    "# Ensure validation feature columns match training columns\n",
    "X_val_final = X_val_color[color_columns]  \n",
    "\n",
    "# Standardize train and validation sets\n",
    "scaler_final = StandardScaler()\n",
    "X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "X_val_final_scaled = scaler_final.transform(X_val_final)\n",
    "\n",
    "# Train RandomForest model using best GMM model (5000 samples, OC range 3-7%)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "y_pred = rf_model.predict(X_val_final_scaled)\n",
    "\n",
    "# Compute performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "\n",
    "# Create prediction plot (without gridlines)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val, y_pred, color='red', marker='^', s=100, label='Validation Samples')\n",
    "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], linestyle='--', color='blue', label='1:1 Line')\n",
    "plt.plot(np.unique(y_val), np.poly1d(np.polyfit(y_val, y_pred, 1))(np.unique(y_val)), color='black', label='Regression Line')\n",
    "\n",
    "plt.xlabel(\"Measured SOC (%)\", fontweight='bold')\n",
    "plt.ylabel(\"Predicted SOC (%)\", fontweight='bold')\n",
    "plt.text(min(y_val), max(y_pred), f'R² = {r2:.2f}', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"GMM_prediction_plot_updated_no_grid.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
